# 多层感知机
在之前的实现过程中，我们用的都是线性的model，这是一个不通用的假设，大部分都不是线性的。
我们可以在输入层和输出层之间添加隐藏层，从而克服线性模型的不足，这种架构通常称为多层感知机

![alt text](image.png)

提问这种改变有用吗
![alt text](image-2.png)
毛用没有，这个和之前的线性model是一个东西，我们可以用之前的线性模型表示所有的这种仿射变换

所以我们得发挥出多层的用处，在每一次的仿射变换之后添加非线性的激活函数
![alt text](image-3.png)
一般来说有了激活函数就不会退化成为线性函数
如果想要构建更加通用的多层感知机，可以添加更多的激活函数和隐藏层

## 激活函数

### relu函数
![alt text](image-4.png)

这个relu函数还有好多的变式
![alt text](image-5.png)

## sigmoid函数
![alt text](image-6.png)
可以将任意范围的输出变成（0，1）的区间

## tanh函数
（双曲正切函数）
![alt text](image-7.png)

# 多层感知机的实现
还是用minst去实现这个代码

## 初始化模型参数
![alt text](image-8.png)
这里我们用的隐藏层的输出参数是256，这个也是可以改变的，但是一般用二的倍数去写，这和内存的机制有关，有利于内存的工作

## 实现rule
![alt text](image-9.png)
没什么好说的，比较容易实现的

## 实现net
我们这里将空间结构忽视，所以先得展开成一个一维的向量
之后就是隐藏层的一些经典操作，别忘了放到激活函数里面
![alt text](image-11.png)